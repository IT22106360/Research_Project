{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62945f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b57d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74834e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\rashm\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\rashm\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\rashm\\.paddlex\\official_models\\PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\rashm\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\rashm\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 542 conv 0.png → 542 conv 0_ocr.json\n",
      "Processed 543 conv 0.png → 543 conv 0_ocr.json\n",
      "Processed 544 conv 0.png → 544 conv 0_ocr.json\n",
      "Processed 545 conv 0.png → 545 conv 0_ocr.json\n",
      "Processed 546 conv 0.png → 546 conv 0_ocr.json\n",
      "Processed 547 conv 0.png → 547 conv 0_ocr.json\n",
      "Processed 548 conv 0.png → 548 conv 0_ocr.json\n",
      "Processed 549 conv 0.png → 549 conv 0_ocr.json\n",
      "Processed 550 conv 0.png → 550 conv 0_ocr.json\n",
      "Processed 551 conv 0.png → 551 conv 0_ocr.json\n",
      "Processed 552 conv 0.png → 552 conv 0_ocr.json\n",
      "Processed 553 conv 0.png → 553 conv 0_ocr.json\n",
      "Processed 554 conv 0.png → 554 conv 0_ocr.json\n",
      "Processed 555 conv 0.png → 555 conv 0_ocr.json\n",
      "Processed 556 conv 0.png → 556 conv 0_ocr.json\n",
      "Processed 557 conv 0.png → 557 conv 0_ocr.json\n",
      "Processed 558 conv 0.png → 558 conv 0_ocr.json\n",
      "Processed 559 conv 0.png → 559 conv 0_ocr.json\n",
      "Processed 560 conv 0.png → 560 conv 0_ocr.json\n",
      "Processed 561 conv 0.png → 561 conv 0_ocr.json\n",
      "Processed 562 conv 0.png → 562 conv 0_ocr.json\n",
      "Processed 563 conv 0.png → 563 conv 0_ocr.json\n",
      "Processed 564 conv 0.png → 564 conv 0_ocr.json\n",
      "Processed 565 conv 0.png → 565 conv 0_ocr.json\n",
      "Processed 566 conv 0.png → 566 conv 0_ocr.json\n",
      "Processed 567 conv 0.png → 567 conv 0_ocr.json\n",
      "Processed 568 conv 0.png → 568 conv 0_ocr.json\n",
      "Processed 569 conv 0.png → 569 conv 0_ocr.json\n",
      "Processed 570 conv 0.png → 570 conv 0_ocr.json\n",
      "Processed 571 conv 0.png → 571 conv 0_ocr.json\n",
      "Processed 572 conv 0.png → 572 conv 0_ocr.json\n",
      "Processed 573 conv 0.png → 573 conv 0_ocr.json\n",
      "Processed 574 conv 0.png → 574 conv 0_ocr.json\n",
      "Processed 575 conv 0.png → 575 conv 0_ocr.json\n",
      "Processed 576 conv 0.png → 576 conv 0_ocr.json\n",
      "Processed 577 conv 0.png → 577 conv 0_ocr.json\n",
      "Processed 578 conv 0.png → 578 conv 0_ocr.json\n",
      "Processed 579 conv 0.png → 579 conv 0_ocr.json\n",
      "Processed 580 conv 0.png → 580 conv 0_ocr.json\n",
      "Processed 581 conv 0.png → 581 conv 0_ocr.json\n",
      "Processed 582 conv 0.png → 582 conv 0_ocr.json\n",
      "Processed 583 conv 0.png → 583 conv 0_ocr.json\n",
      "Processed 584 conv 0.png → 584 conv 0_ocr.json\n",
      "Processed 585 conv 0.png → 585 conv 0_ocr.json\n",
      "Processed 586 conv 0.png → 586 conv 0_ocr.json\n",
      "Processed 587 conv 0.png → 587 conv 0_ocr.json\n",
      "Processed 588 conv 0.png → 588 conv 0_ocr.json\n",
      "Processed 589 conv 0.png → 589 conv 0_ocr.json\n",
      "Processed 590 conv 0.png → 590 conv 0_ocr.json\n",
      "Processed 591 conv 0.png → 591 conv 0_ocr.json\n",
      "Processed 592 conv 0.png → 592 conv 0_ocr.json\n",
      "Processed 593 conv 0.png → 593 conv 0_ocr.json\n",
      "Processed 594 conv 0.png → 594 conv 0_ocr.json\n",
      "Processed 595 conv 0.png → 595 conv 0_ocr.json\n",
      "Processed 596 conv 0.png → 596 conv 0_ocr.json\n",
      "Processed 597 conv 0.png → 597 conv 0_ocr.json\n",
      "Processed 598 conv 0.png → 598 conv 0_ocr.json\n",
      "Processed 599 conv 0.png → 599 conv 0_ocr.json\n",
      "Processed 600 conv 0.png → 600 conv 0_ocr.json\n",
      "Processed 601 conv 0.png → 601 conv 0_ocr.json\n",
      "Processed 603 conv 0.png → 603 conv 0_ocr.json\n",
      "Processed 604 conv 0.png → 604 conv 0_ocr.json\n",
      "Processed 605 conv 0.png → 605 conv 0_ocr.json\n",
      "Processed 606 conv 0.png → 606 conv 0_ocr.json\n",
      "Processed 607 conv 0.png → 607 conv 0_ocr.json\n",
      "Processed 608 conv 0.png → 608 conv 0_ocr.json\n",
      "Processed 609 conv 0.png → 609 conv 0_ocr.json\n",
      "Processed 610 conv 0.png → 610 conv 0_ocr.json\n",
      "Processed 611 conv 0.png → 611 conv 0_ocr.json\n",
      "Processed 612 conv 0.png → 612 conv 0_ocr.json\n",
      "Processed 613 conv 0.png → 613 conv 0_ocr.json\n",
      "Processed 614 conv 0.png → 614 conv 0_ocr.json\n",
      "Processed 615 conv 0.png → 615 conv 0_ocr.json\n",
      "Processed 616 conv 0.png → 616 conv 0_ocr.json\n",
      "Processed 617 conv 0.png → 617 conv 0_ocr.json\n",
      "Processed 618 conv 0.png → 618 conv 0_ocr.json\n",
      "Processed 619 conv 0.png → 619 conv 0_ocr.json\n",
      "Processed 620 conv 0.png → 620 conv 0_ocr.json\n",
      "Processed 621 conv 0.png → 621 conv 0_ocr.json\n",
      "Processed 622 conv 0.png → 622 conv 0_ocr.json\n",
      "Processed 623 conv 0.png → 623 conv 0_ocr.json\n",
      "Processed 624 conv 0.png → 624 conv 0_ocr.json\n",
      "Processed 625 conv 0.png → 625 conv 0_ocr.json\n",
      "Processed 626 conv 0.png → 626 conv 0_ocr.json\n",
      "Processed 627 conv 0.png → 627 conv 0_ocr.json\n",
      "Processed 628 conv 0.png → 628 conv 0_ocr.json\n",
      "Processed 629 conv 0.png → 629 conv 0_ocr.json\n",
      "Processed 630 conv 0.png → 630 conv 0_ocr.json\n",
      "Processed 631 conv 0.png → 631 conv 0_ocr.json\n",
      "Processed 632 conv 0.png → 632 conv 0_ocr.json\n",
      "Processed 633 conv 0.png → 633 conv 0_ocr.json\n",
      "Processed 634 conv 0.png → 634 conv 0_ocr.json\n",
      "Processed 635 conv 0.png → 635 conv 0_ocr.json\n",
      "Processed 636 conv 0.png → 636 conv 0_ocr.json\n",
      "Processed 637 conv 0.png → 637 conv 0_ocr.json\n",
      "Processed 638 conv 0.png → 638 conv 0_ocr.json\n",
      "Processed 639 conv 0.png → 639 conv 0_ocr.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mResized image size (4816x1800) exceeds max_side_limit of 4000. Resizing to fit within limit.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 640 conv 0.png → 640 conv 0_ocr.json\n",
      "Processed 641 conv 0.png → 641 conv 0_ocr.json\n",
      "Processed 642 conv 0.png → 642 conv 0_ocr.json\n",
      "✅ OCR processing complete for all images!\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "input_dir = r\"D:\\Y4 Research\\datasets\\dietary Images\\denoised\"\n",
    "output_dir = r\"D:\\Y4 Research\\datasets\\dietary Images\\denoised_ocr_json\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize PaddleOCR\n",
    "ocr = PaddleOCR(lang='en')\n",
    "\n",
    "# Function to process single image\n",
    "def process_image(image_path):\n",
    "    result = ocr.predict(image_path)\n",
    "    ocr_data = []\n",
    "\n",
    "    # In the latest version, result[0] contains list of lines with structure: [bbox, (text, score)]\n",
    "    for line in result[0]:\n",
    "        bbox = line[0]  # coordinates\n",
    "        text = line[1][0] if isinstance(line[1], (list, tuple)) else str(line[1])\n",
    "        confidence = line[1][1] if isinstance(line[1], (list, tuple)) else 1.0  # default 1.0 if not provided\n",
    "        ocr_data.append({\n",
    "            \"bbox\": bbox,\n",
    "            \"text\": text,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "    return ocr_data\n",
    "\n",
    "# Loop through images\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        ocr_result = process_image(img_path)\n",
    "\n",
    "        json_filename = os.path.splitext(filename)[0] + \"_ocr.json\"\n",
    "        json_path = os.path.join(output_dir, json_filename)\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(ocr_result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"Processed {filename} → {json_filename}\")\n",
    "\n",
    "print(\"✅ OCR processing complete for all images!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research_env)",
   "language": "python",
   "name": "research_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
